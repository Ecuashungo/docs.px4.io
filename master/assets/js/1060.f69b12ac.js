(window.webpackJsonp=window.webpackJsonp||[]).push([[1060],{2217:function(e,t,o){"use strict";o.r(t);var n=o(19),a=Object(n.a)({},(function(){var e=this,t=e.$createElement,o=e._self._c||t;return o("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[o("h1",{attrs:{id:"computer-vision-vio-avoidance"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#computer-vision-vio-avoidance"}},[e._v("#")]),e._v(" Computer Vision (VIO, Avoidance)")]),e._v(" "),o("p",[o("a",{attrs:{href:"https://en.wikipedia.org/wiki/Computer_vision",target:"_blank",rel:"noopener noreferrer"}},[e._v("Computer vision"),o("OutboundLink")],1),e._v(" techniques enable computers to use visual data to make sense of their environment.")]),e._v(" "),o("p",[e._v("PX4 uses computer vision systems (primarily running on "),o("RouterLink",{attrs:{to:"/zh/companion_computer/pixhawk_companion.html"}},[e._v("Companion Computers")]),e._v(") in order to support the following features:")],1),e._v(" "),o("ul",[o("li",[o("a",{attrs:{href:"#optical_flow"}},[e._v("Optical Flow")]),e._v(" provides 2D velocity estimation (using a downward facing camera and a downward facing distance sensor).")]),e._v(" "),o("li",[o("a",{attrs:{href:"#mocap"}},[e._v("Motion Capture")]),e._v(" provides 3D pose estimation using a vision system that is "),o("em",[e._v("external")]),e._v(" to the vehicle. It is primarily used for indoor navigation. It is primarily used for indoor navigation.")]),e._v(" "),o("li",[o("a",{attrs:{href:"#vio"}},[e._v("Visual Inertial Odometry")]),e._v(" provides 3D pose and velocity estimation using an onboard vision system and IMU. It is used for navigation when global position information is absent or unreliable. It is used for navigation when global position information is absent or unreliable.")]),e._v(" "),o("li",[o("a",{attrs:{href:"https://docs.px4.io/en/computer_vision/obstacle_avoidance.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Obstacle Avoidance"),o("OutboundLink")],1),e._v(" provides navigation around obstacles when flying a planned path (currently missions are supported). This uses "),o("a",{attrs:{href:"https://github.com/PX4/avoidance",target:"_blank",rel:"noopener noreferrer"}},[e._v("PX4/avoidance"),o("OutboundLink")],1),e._v(" running on a companion computer. This uses "),o("a",{attrs:{href:"https://github.com/PX4/avoidance",target:"_blank",rel:"noopener noreferrer"}},[e._v("PX4/avoidance"),o("OutboundLink")],1),e._v(" running on a companion computer.")]),e._v(" "),o("li",[o("a",{attrs:{href:"https://docs.px4.io/en/computer_vision/collision_prevention.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Collision Prevention"),o("OutboundLink")],1),e._v(" is used to stop vehicles before they can crash into an obstacle (primarily when flying in manual modes).")])]),e._v(" "),o("blockquote",[o("p",[o("strong",[e._v("Tip")]),e._v(" The "),o("a",{attrs:{href:"https://docs.px4.io/master/en/complete_vehicles/px4_vision_kit.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("PX4 Vision Autonomy Development Kit"),o("OutboundLink")],1),e._v(" (Holybro) is a robust and inexpensive kit for developers working with computer vision on PX4. It comes with "),o("a",{attrs:{href:"https://github.com/PX4/avoidance#obstacle-detection-and-avoidance",target:"_blank",rel:"noopener noreferrer"}},[e._v("PX4 avoidance"),o("OutboundLink")],1),e._v(" software pre-installed, and can be used as the base for your own algorithms.")])]),e._v(" "),o("h2",{attrs:{id:"运动捕捉-mocap"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#运动捕捉-mocap"}},[e._v("#")]),e._v(" 运动捕捉 {#mocap}")]),e._v(" "),o("p",[e._v("Motion Capture (MoCap) is a technique for estimating the 3D "),o("em",[e._v("pose")]),e._v(" (position and orientation) of a vehicle using a positioning mechanism that is "),o("em",[e._v("external")]),e._v(" to the vehicle. MoCap systems most commonly detect motion using infrared cameras, but other types of cameras, Lidar, or Ultra Wideband (UWB) may also be used. MoCap systems most commonly detect motion using infrared cameras, but other types of cameras, Lidar, or Ultra Wideband (UWB)  may also be used.")]),e._v(" "),o("blockquote",[o("p",[o("strong",[e._v("Note")]),e._v(" MoCap is commonly used to navigate a vehicle in situations where GPS is absent (e.g. indoors), and provides position relative to a a "),o("em",[e._v("local")]),e._v(" co-ordinate system.")])]),e._v(" "),o("p",[e._v("For information about MoCap see:")]),e._v(" "),o("ul",[o("li",[o("RouterLink",{attrs:{to:"/zh/ros/external_position_estimation.html"}},[e._v("External Position Estimation")])],1),e._v(" "),o("li",[o("RouterLink",{attrs:{to:"/zh/tutorials/motion-capture-vicon-optitrack.html"}},[e._v("Flying with Motion Capture (VICON, Optitrack)")])],1),e._v(" "),o("li",[o("a",{attrs:{href:"https://docs.px4.io/master/en/advanced_config/tuning_the_ecl_ekf.html#external-vision-system",target:"_blank",rel:"noopener noreferrer"}},[e._v("EKF > External Vision System"),o("OutboundLink")],1)])]),e._v(" "),o("h2",{attrs:{id:"visual-inertial-odometry-vio"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#visual-inertial-odometry-vio"}},[e._v("#")]),e._v(" Visual Inertial Odometry {#vio}")]),e._v(" "),o("p",[e._v("Visual Inertial Odometry (VIO) is used for estimating the 3D "),o("em",[e._v("pose")]),e._v(" (position and orientation) of a moving vehicle relative to a "),o("em",[e._v("local")]),e._v(" starting position. It is commonly used to navigate a vehicle in situations where GPS is absent (e.g. indoors) or unreliable (e.g. when flying under a bridge). It is commonly used to navigate a vehicle in situations where GPS is absent (e.g. indoors) or unreliable (e.g. when flying under a bridge).")]),e._v(" "),o("p",[e._v("VIO uses "),o("a",{attrs:{href:"https://en.wikipedia.org/wiki/Visual_odometry",target:"_blank",rel:"noopener noreferrer"}},[e._v("Visual Odometry"),o("OutboundLink")],1),e._v(" to estimate vehicle "),o("em",[e._v("pose")]),e._v(" from visual information, combined with inertial measurements from an IMU (to correct for errors associated with rapid vehicle movement resulting in poor image capture).")]),e._v(" "),o("blockquote",[o("p",[o("strong",[e._v("Note")]),e._v(" On difference between VIO and "),o("a",{attrs:{href:"#mocap"}},[e._v("MoCap")]),e._v(" is that VIO cameras/IMU are vehicle-based, and additionally provide velocity information.")])]),e._v(" "),o("p",[e._v("For information about VIO see:")]),e._v(" "),o("ul",[o("li",[o("a",{attrs:{href:"https://docs.px4.io/master/en/advanced_config/tuning_the_ecl_ekf.html#external-vision-system",target:"_blank",rel:"noopener noreferrer"}},[e._v("EKF > External Vision System"),o("OutboundLink")],1)]),e._v(" "),o("li",[o("a",{attrs:{href:"https://docs.px4.io/master/en/peripheral/t265_vio.md",target:"_blank",rel:"noopener noreferrer"}},[e._v("T265 Setup guide"),o("OutboundLink")],1)]),e._v(" "),o("li",[o("a",{attrs:{href:"https://docs.px4.io/master/en/flight_controller/snapdragon_flight_software_installation.html#install-snap-vio",target:"_blank",rel:"noopener noreferrer"}},[e._v("Snapdragon > Installation > Install Snap VIO"),o("OutboundLink")],1)])]),e._v(" "),o("h2",{attrs:{id:"optical-flow-optical-flow"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#optical-flow-optical-flow"}},[e._v("#")]),e._v(" Optical Flow {#optical_flow}")]),e._v(" "),o("p",[o("a",{attrs:{href:"https://docs.px4.io/en/sensor/optical_flow.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Optical Flow"),o("OutboundLink")],1),e._v(" provides 2D velocity estimation (using a downward facing camera and a downward facing distance sensor).")]),e._v(" "),o("p",[e._v("For information about optical flow see:")]),e._v(" "),o("ul",[o("li",[o("a",{attrs:{href:"https://docs.px4.io/master/en/sensor/optical_flow.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Optical Flow"),o("OutboundLink")],1),e._v(" "),o("ul",[o("li",[o("a",{attrs:{href:"https://docs.px4.io/master/en/sensor/px4flow.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("PX4Flow Smart Camera"),o("OutboundLink")],1)])])]),e._v(" "),o("li",[o("a",{attrs:{href:"https://docs.px4.io/master/en/advanced_config/tuning_the_ecl_ekf.html#optical-flow",target:"_blank",rel:"noopener noreferrer"}},[e._v("EKF > Optical Flow"),o("OutboundLink")],1)])]),e._v(" "),o("h2",{attrs:{id:"external-resources"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#external-resources"}},[e._v("#")]),e._v(" External Resources")]),e._v(" "),o("ul",[o("li",[o("a",{attrs:{href:"https://github.com/robin-shaun/XTDrone/blob/master/README.en.md",target:"_blank",rel:"noopener noreferrer"}},[e._v("XTDrone"),o("OutboundLink")],1),e._v(" - ROS + PX4 simulation environment for computer vision. The "),o("a",{attrs:{href:"https://www.yuque.com/xtdrone/manual_en",target:"_blank",rel:"noopener noreferrer"}},[e._v("XTDrone Manual"),o("OutboundLink")],1),e._v(" has everything you need to get started!")])])])}),[],!1,null,null,null);t.default=a.exports}}]);