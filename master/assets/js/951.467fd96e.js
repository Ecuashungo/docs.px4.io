(window.webpackJsonp=window.webpackJsonp||[]).push([[951],{1951:function(e,t,n){"use strict";n.r(t);var a=n(18),r=Object(a.a)({},(function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[n("h1",{attrs:{id:"시각-관성-주행거리-측정-vio"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#시각-관성-주행거리-측정-vio"}},[e._v("#")]),e._v(" 시각 관성 주행거리 측정(VIO)")]),e._v(" "),n("p",[n("em",[e._v("Visual Inertial Odometry")]),e._v(" (VIO)는 "),n("em",[e._v("지역적")]),e._v(" 시작 위치를 기준으로 움직이는 기체의 3차원 "),n("em",[e._v("자세")]),e._v(" (지역적 위치 및 방향)와 "),n("em",[e._v("속도")]),e._v("를 추정하는 "),n("RouterLink",{attrs:{to:"/ko/computer_vision/"}},[e._v("컴퓨터 비전")]),e._v(" 기술입니다. GPS가 없거나 신뢰할 수없는 상황 (예 : 실내 또는 다리 아래에서 비행시)에서 기체 내비게이션용으로 사용됩니다.")],1),e._v(" "),n("p",[e._v("VIO는 기체 IMU의 관성 측정과 결합된 카메라 이미지에서 기체의 "),n("em",[e._v("자세")]),e._v("를 추정하기 위하여 "),n("a",{attrs:{href:"https://en.wikipedia.org/wiki/Visual_odometry",target:"_blank",rel:"noopener noreferrer"}},[e._v("시각적 Odometry"),n("OutboundLink")],1),e._v("를 사용합니다 (이미지 캡처 불량을 초래하는 빠른 기체 이동과 관련된 오류를 수정함).")]),e._v(" "),n("p",[n("em",[e._v("지원 가능한")]),e._v(" VIO 설정을 사용하도록 PX4와 보조 컴퓨터 설정방법을 설명합니다.")]),e._v(" "),n("iframe",{attrs:{width:"650",height:"365",src:"https://www.youtube.com/embed/gWtrka2mK7U",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:"",mark:"crwd-mark"}}),e._v(" "),n("div",{staticClass:"custom-block tip"},[n("p",{staticClass:"custom-block-title"},[e._v("TIP")]),e._v(" "),n("p",[e._v("위의 "),n("a",{attrs:{href:"https://auterion.com/enabling_uav_navigation_in_environments_with_limited_or_no_gps_signal/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Auterion 제품 동영상"),n("OutboundLink")],1),e._v("은 "),n("a",{attrs:{href:"#supported_setup"}},[e._v("지원 가능한 설정")]),e._v("을 사용하여 비행중인기체를 보여줍니다.")])]),e._v(" "),n("div",{staticClass:"custom-block note"},[n("p",{staticClass:"custom-block-title"},[e._v("Note")]),e._v(" "),n("p",[e._v("이 (지원되는) 솔루션은 ROS를 사용하여 VIO 정보를 PX4로 라우팅합니다. PX4 자체는 적절한 "),n("RouterLink",{attrs:{to:"/ko/ros/external_position_estimation.html#px4-mavlink-integration"}},[e._v("MAVLink 인터페이스")]),e._v("를 통하여 제공되는 메시지 소스는 신경 쓰지 않습니다.")],1)]),e._v(" "),n("p",[n("span",{attrs:{id:"supported_setup"}})]),e._v(" "),n("h2",{attrs:{id:"지원-가능한-설정"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#지원-가능한-설정"}},[e._v("#")]),e._v(" 지원 가능한 설정")]),e._v(" "),n("p",[e._v("지원 가능한 설정은 "),n("RouterLink",{attrs:{to:"/ko/peripherals/camera_t265_vio.html"}},[e._v("T265 Intel Realsense 추적 카메라")]),e._v(" 및 ROS (보조 컴퓨터에서 실행)를 사용하여 PX4에 주행 거리 측정 정보를 제공합니다. The Auterion "),n("a",{attrs:{href:"https://github.com/Auterion/VIO_bridge",target:"_blank",rel:"noopener noreferrer"}},[e._v("VIO bridge ROS node"),n("OutboundLink")],1),e._v(" provides a bridge between this (particular) camera and ROS.")],1),e._v(" "),n("h3",{attrs:{id:"카메라-장착"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#카메라-장착"}},[e._v("#")]),e._v(" 카메라 장착")]),e._v(" "),n("p",[e._v("카메라를 보조 컴퓨터에 연결하고 프레임에 장착합니다.")]),e._v(" "),n("ul",[n("li",[e._v("제공된 케이블을 사용하여 "),n("RouterLink",{attrs:{to:"/ko/peripherals/camera_t265_vio.html"}},[e._v("T265 Intel Realsense 추적 카메라")]),e._v("를 연결합니다.")],1),e._v(" "),n("li",[e._v("가능하면 렌즈가 아래쪽을 향하도록 카메라를 장착하십시오 (기본값).")]),e._v(" "),n("li",[e._v("카메라는 진동에 매우 민감합니다. 부드러운 장착이 권장됩니다 (예 : 방진폼 사용).")])]),e._v(" "),n("h3",{attrs:{id:"ros-vio-설정"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#ros-vio-설정"}},[e._v("#")]),e._v(" ROS/VIO 설정")]),e._v(" "),n("p",[e._v("Bridge, ROS 및 PX4를 설정 :")]),e._v(" "),n("ul",[n("li",[e._v("보조 컴퓨터에서 "),n("RouterLink",{attrs:{to:"/ko/ros/mavros_installation.html"}},[e._v("MAVROS")]),e._v("를 설치하고 설정합니다.")],1),e._v(" "),n("li",[e._v("Auterion "),n("a",{attrs:{href:"https://github.com/Auterion/VIO_bridge",target:"_blank",rel:"noopener noreferrer"}},[e._v("VIO 브리지 ROS 노드"),n("OutboundLink")],1),e._v("를 가져옵니다.\n"),n("ul",[n("li",[e._v("catkin 작업 공간에서이 저장소를 복제하십시오."),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("cd ~/catkin_ws/src\n")])])])])])])]),e._v(" "),n("p",[e._v("git clone https://github.com/Auterion/VIO.git\n```")]),e._v(" "),n("ul",[n("li",[e._v("패키지 빌드:"),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("cd ~/catkin_ws/src\n")])])])])]),e._v(" "),n("p",[e._v("catkin build px4_realsense_bridge\n```")]),e._v(" "),n("ul",[n("li",[n("p",[e._v("필요한 경우 카메라 방향을 설정합니다.")]),e._v(" "),n("ul",[n("li",[e._v("카메라가 렌즈가 아래를 향하도록 장착 된 경우 VIO 브리지는 구성이 필요하지 않습니다 (기본값).")]),e._v(" "),n("li",[e._v("다른 방향의 경우 아래 섹션에서 "),n("a",{attrs:{href:"https://github.com/Auterion/VIO/blob/master/launch/bridge_mavros.launch",target:"_blank",rel:"noopener noreferrer"}},[e._v("bridge_mavros.launch"),n("OutboundLink")],1),e._v("를 수정합니다."),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("node")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("pkg")]),n("span",{pre:!0,attrs:{class:"token attr-value"}},[n("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),n("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("type")]),n("span",{pre:!0,attrs:{class:"token attr-value"}},[n("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("static_transform_publisher"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),n("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("name")]),n("span",{pre:!0,attrs:{class:"token attr-value"}},[n("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("tf_baseLink_cameraPose"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v("\n    "),n("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("args")]),n("span",{pre:!0,attrs:{class:"token attr-value"}},[n("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("0 0 0 0 1.5708 0 base_link camera_pose_frame 1000"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("/>")])]),e._v("\n")])])])])]),e._v(" "),n("p",[e._v("카메라 ROS 프레임 "),n("code",[e._v("camera_pose_frame")]),e._v("을 mavros 드론 프레임 "),n("code",[e._v("base_link")]),e._v("에 연결하는 정적 변환입니다.")]),e._v(" "),n("ul",[n("li",[e._v("처음 세 개의 "),n("code",[e._v("인수")]),e._v("는 비행 컨트롤러의 중심에서 카메라까지의 미터 단위로 "),n("em",[e._v("변환")]),e._v(" x, y, z를 지정합니다. 예를 들어 카메라가 컨트롤러 앞 10cm, 위쪽 4cm 인 경우 처음 세 숫자는 [0.1, 0, 0.04, ...]입니다.")]),e._v(" "),n("li",[e._v("다음 세 개의 "),n("code",[e._v("인수")]),e._v("는 라디안 (요, 피치, 롤)으로 회전을 지정합니다. 따라서 "),n("code",[e._v("[... 0, 1.5708, 0]")]),e._v("은 90도 내림(지면을 향함)을 의미합니다. 정면을 바라보는 것은 [... 0 0 0]입니다.")])])]),e._v(" "),n("li",[n("p",[e._v("PX4 EKF2 추정기를 조정하려면 "),n("a",{attrs:{href:"#ekf2_tuning"}},[e._v("아래")]),e._v(" 지침을 따르십시오.")])]),e._v(" "),n("li",[n("p",[e._v("적절한 시작 파일과 함께 "),n("code",[e._v("roslaunch")]),e._v("를 호출하여 VIO를 실행합니다.")]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("cd ~/catkin_ws/src\n")])])])])]),e._v(" "),n("p",[e._v("roslaunch px4_realsense_bridge bridge_mavros.launch")]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v('실행 파일 옵션은 다음과 같습니다.\n- [bridge_mavros.launch](https://github.com/Auterion/VIO/blob/master/launch/bridge_mavros.launch) : 대부분의 경우 기체에 사용합니다 (브리지 및 MAVROS 시작).\n- [bridge.launch](https://github.com/Auterion/VIO/blob/master/launch/bridge.launch) : 다른 구성 요소가 MAVROS 시작을 담당하는 경우 사용 (브리지 시작만)\n- [bridge.launch](https://github.com/Auterion/VIO/blob/master/launch/bridge_mavros_sitl.launch) : 다른 구성 요소가 MAVROS 시작을 담당하는 경우 사용 (브리지 시작만)\n- 비행 컨트롤러 연결을 확인하십시오.\n\n:::tip\n*QGroundControl* [MAVLink Inspector](https://docs.qgroundcontrol.com/en/analyze_view/mavlink_inspector.html)를 사용하여 `ODOMETRY` 또는 `VISION_POSITION_ESTIMATE` 메시지를 받고 있는지 확인할 수 있습니다.(또는 구성 요소 ID가 197 (`MAV_COMP_ID_VISUAL_INERTIAL_ODOMETRY`) 인 `HEARTBEAT ` 메시지)\n:::\n- 첫 비행전에 [VIO가 올바르게 설정되었는지 확인하십시오](#verify_estimate)!\n\n<span id="ekf2_tuning"></span>\n### PX4 튜닝\n\nThe following parameters must be set to use external position information with EKF2.\n\n| Parameter                                                                                                                                                                                                                          | Setting for External Position Estimation                                                                                                               |\n| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| [EKF2_AID_MASK](../advanced_config/parameter_reference.md#EKF2_AID_MASK)                                                                                                                                                         | Set *vision position fusion*, *vision velocity fusion*, *vision yaw fusion* and *external vision rotation* accoring to your desired fusion model.      |\n| [EKF2_HGT_MODE](../advanced_config/parameter_reference.md#EKF2_HGT_MODE)                                                                                                                                                         | Set to *Vision* to use the vision a primary source for altitude estimation.                                                                            |\n| [EKF2_EV_DELAY](../advanced_config/parameter_reference.md#EKF2_EV_DELAY)                                                                                                                                                         | Set to the difference between the timestamp of the measurement and the "actual" capture time. For more information see [below](#tuning-EKF2_EV_DELAY). |\n| [EKF2_EV_POS_X](../advanced_config/parameter_reference.md#EKF2_EV_POS_X), [EKF2_EV_POS_Y](../advanced_config/parameter_reference.md#EKF2_EV_POS_Y), [EKF2_EV_POS_Z](../advanced_config/parameter_reference.md#EKF2_EV_POS_Z) | Set the position of the vision sensor with respect to the vehicles body frame.                                                                         |\n\nThese can be set in *QGroundControl* > **Vehicle Setup > Parameters > EKF2** (remember to reboot the flight controller in order for parameter changes to take effect).\n\nFor more detailed/additional information, see: [ECL/EKF Overview & Tuning > External Vision System](../advanced_config/tuning_the_ecl_ekf.md#external-vision-system).\n\n<span id="tuning-EKF2_EV_DELAY"></span>\n#### Tuning EKF2_EV_DELAY\n\n[EKF2_EV_DELAY](../advanced_config/parameter_reference.md#EKF2_EV_DELAY) is the *Vision Position Estimator delay relative to IMU measurements*. In other words, it is the difference between the vision system timestamp and the "actual" capture time that would have been recorded by the IMU clock (the "base clock" for EKF2).\n\nTechnically this can be set to 0 if there is correct timestamping (not just arrival time) and timesync (e.g NTP) between MoCap and (for example) ROS computers. In reality, this may need some empirical tuning becuase delays in the communication chain are very setup-specific. It is rare that a system is setup with an entirely synchronised chain!\n\nA rough estimate of the delay can be obtained from logs by checking the offset between IMU rates and the EV rates:\n\n![ekf2_ev_delay log](../../assets/ekf2/ekf2_ev_delay_tuning.png)\n\n:::note\nA plot of external data vs. onboard estimate (as above) can be generated using [FlightPlot](../dev_log/flight_log_analysis.md#flightplot) or similar flight analysis tools.\n:::\n\nThe value can further be tuned by varying the parameter to find the value that yields the lowest EKF innovations during dynamic maneuvers.\n\n<span id="verify_estimate"></span>\n## Check/Verify VIO Estimate\n\nPerform the following checks to verify that VIO is working properly *before* your first flight:\n\n* Set the PX4 parameter `MAV_ODOM_LP` to 1. PX4 will then stream back the received external pose as MAVLink [ODOMETRY](https://mavlink.io/en/messages/common.html#ODOMETRY) messages. You can check these MAVLink messages with the *QGroundControl* [MAVLink Inspector](https://docs.qgroundcontrol.com/en/analyze_view/mavlink_inspector.html)\n* Yaw the vehicle until the quaternion of the `ODOMETRY` message is very close to a unit quaternion (w=1, x=y=z=0).\n* At this point the body frame is aligned with the reference frame of the external pose system.\n* If you do not manage to get a quaternion close to the unit quaternion without rolling or pitching your vehicle, your frame probably still has a pitch or roll offset. Do not proceed if this is the case and check your coordinate frames again.\n* Once aligned you can pick the vehicle up from the ground and you should see the position\'s z coordinate decrease. Moving the vehicle in forward direction, should increase the position\'s x coordinate. While moving the vehicle to the right should increase the y coordinate.\n* Check that linear velocities in the message are in expressed in the *FRD* body frame reference frame.\n* Set the PX4 parameter `MAV_ODOM_LP` back to 0. PX4 will stop streaming the `ODOMETRY` message back.\n\nIf those steps are consistent, you can try your first flight:\n1. Put the vehicle on the ground and start streaming `ODOMETRY` feedback (as above). Lower your throttle stick and arm the motors.\n\n At this point, with the left stick at the lowest position, switch to position control. You should have a green light. The green light tells you that position feedback is available and position control is now activated.\n\n1. Put the throttle stick in the middle (the dead zone) so that the vehicle maintains its altitude. Raising the stick will increase the reference altitude while lowering the value will decrease it. Similarly the other stick will change position over ground.\n1. Increase the value of the throttle stick and the vehicle will take off, put it back to the middle right after.\n1. Confirm that the vehicle can hold its position.\n\n\n## Troubleshooting\n\nFirst make sure MAVROS is able to connect successfully to the flight controller.\n\nIf it is connecting properly common problems/solutions are:\n\n- **Problem:** I get drift / flyaways when the drone flies, but not when I carry it around with the props off.\n- If using the [T265](../peripherals/camera_t265_vio.md) try soft-mounting it (this camera is very sensitive to high frequency vibrations).\n\n- **Problem:** I get toilet-bowling when VIO is enabled.\n- Make sure the orientation of the camera matches the transform in the launch file. Use the *QGroundControl* [MAVLink Inspector](https://docs.qgroundcontrol.com/en/analyze_view/mavlink_inspector.html) to verify that the velocities in the `ODOMETRY` message coming from MAVROS are aligned to the FRD coordinate system.\n\n- **Problem:** I want to use vision position to do loop closing, and also want to run GPS.\n- This is really difficult, because when they disagree it will confuse the EKF. From testing it is more reliable to just use vision velocity (if you figure out a way to make this configuration reliable, let us know).\n\n\n## Developer Information\n\nDevelopers who are interested in extending this implementation (or writing a different one, which might not depend on ROS) should see [Using Vision or Motion Capture Systems for Position Estimation](../ros/external_position_estimation.md).\n\nThis topic also explains how to configure VIO for use with the LPE Estimator (deprecated).\n\n\n## Further Information\n\n- [ECL/EKF Overview & Tuning > External Vision System](../advanced_config/tuning_the_ecl_ekf.md#external-vision-system)\n- [Snapdragon > Installation > Install Snap VIO](../flight_controller/snapdragon_flight_software_installation.md#install-snap-vio)')])])])])}),[],!1,null,null,null);t.default=r.exports}}]);