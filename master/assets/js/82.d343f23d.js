(window.webpackJsonp=window.webpackJsonp||[]).push([[82],{1125:function(e,t,a){e.exports=a.p+"assets/img/trigger_pins.87ed0f77.png"},1126:function(e,t,a){e.exports=a.p+"assets/img/seagull_sync2.5b9a14dd.png"},1127:function(e,t,a){e.exports=a.p+"assets/img/qgc_test_camera.062e3c2b.png"},1128:function(e,t,a){e.exports=a.p+"assets/img/photogrammetry.4b5c0077.png"},1129:function(e,t,a){e.exports=a.p+"assets/img/qgc_survey_polygon.97788c03.jpeg"},1130:function(e,t,a){e.exports=a.p+"assets/img/qgc_survey_parameters.dbf2bf87.jpg"},1131:function(e,t,a){e.exports=a.p+"assets/img/qgc_geotag.f7b0a365.png"},1132:function(e,t,a){e.exports=a.p+"assets/img/geotag.2d9fb330.jpg"},1133:function(e,t,a){e.exports=a.p+"assets/img/sequence_diagram.2624c5c0.jpg"},2078:function(e,t,a){"use strict";a.r(t);var r=a(19),o=Object(r.a)({},(function(){var e=this,t=e.$createElement,r=e._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h1",{attrs:{id:"카메라-트리거"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#카메라-트리거"}},[e._v("#")]),e._v(" 카메라 트리거")]),e._v(" "),r("p",[e._v("The camera trigger driver allows the use of the AUX ports to send out pulses in order to trigger a camera.")]),e._v(" "),r("p",[e._v("In addition to a pulse being sent out, the MAVLink "),r("a",{attrs:{href:"https://mavlink.io/en/messages/common.html#CAMERA_TRIGGER",target:"_blank",rel:"noopener noreferrer"}},[e._v("CAMERA_TRIGGER"),r("OutboundLink")],1),e._v(" message is published containing a sequence number (i.e. the current session's image sequence number) and the corresponding timestamp. This timestamp can be used for several applications, including: timestamping photos for aerial surveying and reconstruction, synchronising a multi-camera system or visual-inertial navigation.")]),e._v(" "),r("p",[e._v("Cameras can also (optionally) use the flight controller "),r("a",{attrs:{href:"#camera_capture"}},[e._v("camera capture pin")]),e._v(" to signal the exact moment that a photo/frame is taken. This allows more precise mapping of images to GPS position for geotagging, or the right IMU sample for VIO synchronization, etc.")]),e._v(" "),r("h2",{attrs:{id:"트리거-설정-trigger-setup-qgc"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#트리거-설정-trigger-setup-qgc"}},[e._v("#")]),e._v(" 트리거 설정 {#trigger_setup_qgc}")]),e._v(" "),r("p",[e._v("Camera triggering is usually configured from the "),r("em",[e._v("QGroundControl")]),e._v(" "),r("a",{attrs:{href:"https://docs.qgroundcontrol.com/en/SetupView/Camera.html#px4-camera-setup",target:"_blank",rel:"noopener noreferrer"}},[e._v("Vehicle Setup > Camera"),r("OutboundLink")],1),e._v(" section.")]),e._v(" "),r("p",[r("img",{attrs:{src:a(1125),alt:"Trigger pins"}})]),e._v(" "),r("p",[e._v("The different "),r("a",{attrs:{href:"#trigger_mode"}},[e._v("trigger modes")]),e._v(", "),r("a",{attrs:{href:"#trigger_backend"}},[e._v("backend interfaces")]),e._v(" and "),r("a",{attrs:{href:"#hardware_setup"}},[e._v("hardware setup")]),e._v(" are described below (these can also be set directly from "),r("RouterLink",{attrs:{to:"/ko/advanced_config/parameters.html"}},[e._v("parameters")]),e._v(").")],1),e._v(" "),r("blockquote",[r("p",[r("strong",[e._v("Note")]),e._v(" The camera settings section is not available by default for FMUv2-based flight controllers (e.g. 3DR Pixhawk) because the camera module is not automatically included in firmware. For more information see "),r("RouterLink",{attrs:{to:"/ko/advanced_config/parameters.html#parameter-not-in-firmware"}},[e._v("Finding/Updating Parameters > Parameters Not In Firmware")]),e._v(".")],1)]),e._v(" "),r("h2",{attrs:{id:"트리거-모드-trigger-mode"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#트리거-모드-trigger-mode"}},[e._v("#")]),e._v(" 트리거 모드 {#trigger_mode}")]),e._v(" "),r("p",[e._v("Four different modes are supported, controlled by the "),r("RouterLink",{attrs:{to:"/ko/advanced_config/parameter_reference.html#TRIG_MODE"}},[e._v("TRIG_MODE")]),e._v(" parameter:")],1),e._v(" "),r("p",[e._v("MAVLink 명령 ` MAV_CMD_DO_TRIGGER_CONTROL </ 0>을 사용하여 활성화 및 비활성화 할 수있는 기본 간격계와 같은 기능을합니다. 자세한 내용은 "),r("a",{attrs:{href:"#command_interface"}},[e._v(" 명령 인터페이스 </ 0>를 참조하십시오.\n"),e._v(" "),r("tr",[r("td",[e._v("2")]),e._v(" "),r("td",[e._v("자동 노출계를 지속적으로 켭니다.")])])])]),e._v(" "),r("tr",[r("td",[e._v("3")]),e._v(" "),r("td",[e._v("거리를 기반으로 트리거합니다. 설정 한 수평 거리를 초과 할 때마다 촬영됩니다. 그러나 두 샷 사이의 최소 시간 간격은 설정된 트리거 간격에 의해 제한됩니다.")])]),e._v(" "),r("tr",[r("td",[e._v("4")]),e._v(" "),r("td",[e._v("임무 모드에서 측량을 비행 할 때 자동으로 트리거됩니다.")])]),e._v(" "),r("blockquote",[r("p",[r("strong",[e._v("Info")]),e._v(" If it is your first time enabling the camera trigger app, remember to reboot after changing the "),r("code",[e._v("TRIG_MODE` parameter.")])])]),e._v(" "),r("h2",{attrs:{id:"트리거-하드웨어-설정-hardware-setup"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#트리거-하드웨어-설정-hardware-setup"}},[e._v("#")]),e._v(" 트리거 하드웨어 설정 {#hardware_setup}")]),e._v(" "),r("p",[e._v("The pins used to trigger image capture for GPIO, PWM or Seagull-based triggering (i.e. when not using a MAVLink camera) are set using the "),r("RouterLink",{attrs:{to:"/ko/advanced_config/parameter_reference.html#TRIG_PINS"}},[e._v("TRIG_PINS")]),e._v(" parameter. The default is 56, which means that trigger is enabled on "),r("em",[e._v("FMU")]),e._v(" pins 5 and 6.")],1),e._v(" "),r("blockquote",[r("p",[r("strong",[e._v("Note")]),e._v(" On a Pixhawk flight controller that has both FMU and I/O boards these FMU pins map to "),r("code",[e._v("AUX5")]),e._v(" and "),r("code",[e._v("AUX6")]),e._v(" (e.g. Pixhawk 4, CUAV v5+). On a controller that only has an FMU, the pins map to "),r("code",[e._v("MAIN5")]),e._v(" and "),r("code",[e._v("MAIN6")]),e._v(" (e.g. Pixhawk 4 mini, CUAV v5 nano). At time of writing triggering only works on FMU pins - you can't trigger a camera using pins on the I/O board.")])]),e._v(" "),r("p",[r("span")]),e._v(" "),r("blockquote",[r("p",[r("strong",[e._v("Warning")]),e._v(" With "),r("code",[e._v("TRIG_PINS=56")]),e._v(" (default) you can use the AUX pins 1 to 4 as actuator outputs (for servos/ESCs). With "),r("code",[e._v("TRIG_PINS=78")]),e._v(", you can use the AUX pins 1-6 as actuator outputs. Any other combination of pins can be selected, but this will disable use of the other FMU pins as outputs.")])]),e._v(" "),r("h2",{attrs:{id:"트리거-인터페이스-백엔드-trigger-backend"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#트리거-인터페이스-백엔드-trigger-backend"}},[e._v("#")]),e._v(" 트리거 인터페이스 백엔드 {#trigger_backend}")]),e._v(" "),r("p",[e._v("The camera trigger driver supports several backends - each for a specific application, controlled by the "),r("RouterLink",{attrs:{to:"/ko/advanced_config/parameter_reference.html#TRIG_INTERFACE"}},[e._v("TRIG_INTERFACE")]),e._v(" parameter:")],1),e._v(" "),r("p",[e._v("enables the GPIO interface. AUX 출력은 매  TRIG_INTERVAL </ 1> 지속 시간마다 ("),r("code",[e._v('TRIG_POLARITY </ 0> 매개 변수에 따라) 높거나 낮게 펄스됩니다. 이것은 대부분의 표준 머신 비전 카메라를 직접 트리거하는 데 사용될 수 있습니다. PX4FMU 시리즈 하드웨어 (Pixhawk, Pixracer 등)에서 AUX 핀의 신호 레벨은 3.3v입니다.</td> </tr> <tr> <td>2</td> <td>Seagull MAP2 인터페이스를 활성화합니다. 이를 통해 <a href="http://www.seagulluav.com/product/seagull-map2/"> Seagull MAP2 </ 0>를 사용하여 지원되는 여러 카메라에 연결할 수 있습니다. Pin/Channel 1 (camera trigger) and Pin/Channel 2 (mode selector) of the MAP2 should be connected to the lower and higher AUX pins of <code>TRIG_PINS')]),e._v(", respectively (therefore, channel/pin 1 to AUX 5 and channel/pin 2 to AUX 6 by default). Using Seagull MAP2, PX4 also supports automatic power control and keep-alive functionalities of Sony Multiport cameras like the QX-1.")]),e._v(" "),r("h2",{attrs:{id:"기타-패러미터들"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#기타-패러미터들"}},[e._v("#")]),e._v(" 기타 패러미터들")]),e._v(" "),r("table",[r("thead",[r("tr",[r("th",[e._v("Parameter")]),e._v(" "),r("th",[e._v("Description")])])]),e._v(" "),r("tbody",[r("tr",[r("td",[r("RouterLink",{attrs:{to:"/ko/advanced_config/parameter_reference.html#TRIG_POLARITY"}},[e._v("TRIG_POLARITY")])],1),e._v(" "),r("td",[e._v("GPIO 인터페이스를 사용하는 동안에 만 관련됩니다. 트리거 핀의 극성을 설정합니다. 액티브 하이는 핀이 로우로 정상적으로 당겨지고 트리거 이벤트에서 하이로 풀링됨을 의미합니다. 액티브 로우는 반대의 경우도 마찬가지입니다.")])]),e._v(" "),r("tr",[r("td",[r("RouterLink",{attrs:{to:"/ko/advanced_config/parameter_reference.html#TRIG_INTERVAL"}},[e._v("TRIG_INTERVAL")])],1),e._v(" "),r("td",[e._v("두 개의 연속 트리거 이벤트 사이의 시간을 밀리 초 단위로 정의합니다.")])]),e._v(" "),r("tr",[r("td",[r("RouterLink",{attrs:{to:"/ko/advanced_config/parameter_reference.html#TRIG_ACT_TIME"}},[e._v("TRIG_ACT_TIME")])],1),e._v(" "),r("td",[e._v('트리거 핀이 "활성"상태로 유지되어 중립으로 돌아 가기 전의 시간을 밀리 초 단위로 정의합니다. PWM 모드에서는 50Hz PWM 신호에 항상 활성화 펄스를 맞출 수 있도록 최소값이 40ms로 제한됩니다.')])])])]),e._v(" "),r("p",[e._v("The full list of parameters pertaining to the camera trigger module can be found on the "),r("RouterLink",{attrs:{to:"/ko/advanced_config/parameter_reference.html#camera-trigger"}},[e._v("parameter reference")]),e._v(" page.")],1),e._v(" "),r("h2",{attrs:{id:"camera-capture-camera-capture"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#camera-capture-camera-capture"}},[e._v("#")]),e._v(" Camera Capture {#camera_capture}")]),e._v(" "),r("p",[e._v("Cameras can also (optionally) use the flight controller "),r("a",{attrs:{href:"#camera_capture"}},[e._v("camera capture pin")]),e._v(" to signal the exact moment when a photo/frame is taken. This allows more precise mapping of images to GPS position for geotagging, or the right IMU sample for VIO synchronization, etc.")]),e._v(" "),r("p",[e._v("Camera capture/feedback is enabled in PX4 by setting "),r("RouterLink",{attrs:{to:"/ko/advanced_config/parameter_reference.html#CAM_CAP_FBACK"}},[e._v("CAM_CAP_FBACK = 1")]),e._v(". The capture pin used depends on the hardware:")],1),e._v(" "),r("ul",[r("li",[e._v("Pixhawk FMUv5x boards use the board-specific camera capture pin (PI0).")]),e._v(" "),r("li",[e._v("Other board use FMU PWM pin 6 (hardcoded) for camera capture.")])]),e._v(" "),r("p",[e._v("PX4 detects a rising edge with the appropriate voltage level on the camera capture pin (for Pixhawk flight controllers this is normally 3.3V). If the camera isn't outputing an appropriate voltage, then additional circuitry will be required to make the signal compatible.")]),e._v(" "),r("p",[e._v("Cameras that have a hotshoe connector (for connecting a flash) can usually be connected via a hotshoe-adaptor. For example, the "),r("a",{attrs:{href:"https://www.seagulluav.com/product/seagull-sync2/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Seagull #SYNC2 Universal Camera Hot Shoe Adapter"),r("OutboundLink")],1),e._v(" is an optocoupler that decouples and shifts the flash voltage to the Pixhawk voltage. This slides into the flash slot on the top of the camera. The red and black ouptputs are connected to the servo rail/ground and the white wire is connected to the input capture pin.")]),e._v(" "),r("p",[r("img",{attrs:{src:a(1126),alt:"Seagull SYNC#2"}})]),e._v(" "),r("blockquote",[r("p",[r("strong",[e._v("Note")]),e._v(" PX4 emits the MAVLink "),r("a",{attrs:{href:"https://mavlink.io/en/messages/common.html#CAMERA_TRIGGER",target:"_blank",rel:"noopener noreferrer"}},[e._v("CAMERA_TRIGGER"),r("OutboundLink")],1),e._v(" message on both camera trigger and camera capture. If camera capture is configured, the timestamp from the camera capture driver is used, otherwise the triggering timestamp.")])]),e._v(" "),r("h2",{attrs:{id:"command-interface-command-interface"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#command-interface-command-interface"}},[e._v("#")]),e._v(" Command Interface {#command_interface}")]),e._v(" "),r("p",[r("strong",[e._v("TODO : NEEDS UPDATING updating")])]),e._v(" "),r("p",[e._v("The camera trigger driver supports several commands:")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://mavlink.io/en/messages/common.html#MAV_CMD_DO_TRIGGER_CONTROL",target:"_blank",rel:"noopener noreferrer"}},[e._v("MAV_CMD_DO_TRIGGER_CONTROL"),r("OutboundLink")],1),e._v(' - Accepted in "command controlled" mode ('),r("code",[e._v("TRIG_MODE")]),e._v(" 1).")]),e._v(" "),r("p",[e._v("트리거 사이클 시간 (밀리 초 단위) (` TRIG_INTERVAL </ 0> 매개 변수 설정)")]),r("tr",[r("td",[e._v("Param #3")]),e._v(" "),r("td",[e._v("시퀀스 재설정 (이미지 시퀀스 번호를 재설정하려면 1로 설정하고 현재 시퀀스 번호를 유지하려면 0으로 설정)")])]),e._v(" "),r("p"),e._v(" "),r("p",[r("a",{attrs:{href:"https://mavlink.io/en/messages/common.html#MAV_CMD_DO_DIGICAM_CONTROL"}},[e._v("MAV_CMD_DO_DIGICAM_CONTROL")]),e._v(" - Accepted in all modes.\nThis is used by the GCS to test-shoot the camera from the user interface.\nThe trigger driver does not yet support all camera control parameters defined by the MAVLink spec.")]),e._v(" "),r("table",[r("thead",[r("tr",[r("th",[e._v("Command Parameter")]),e._v(" "),r("th",[e._v("Description")])])]),e._v(" "),r("tbody",[r("tr",[r("td",[e._v("Param #5")]),e._v(" "),r("td",[e._v("원샷 명령을 트리거합니다 (단일 이미지 프레임을 트리거하려면 1로 설정).")])])])]),e._v(" "),r("p",[r("a",{attrs:{href:"https://mavlink.io/en/messages/common.html#MAV_CMD_DO_SET_CAM_TRIGG_DIST"}},[e._v("MAV_CMD_DO_SET_CAM_TRIGG_DIST")]),e._v(' - Accepted in "mission controlled" mode ('),r("code",[e._v("TRIG_MODE` 4)")])]),e._v(" "),r("p",[e._v("This command is autogenerated during missions to trigger the camera based on survey missions from the GCS.")]),e._v(" "),r("h2",{attrs:{id:"testing-trigger-functionality"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#testing-trigger-functionality"}},[e._v("#")]),e._v(" Testing Trigger Functionality")]),e._v(" "),r("ol",[r("li",[r("p",[e._v("PX4 콘솔에서 : "),r("code",[e._v("카메라_트리거 테스트")])])]),e._v(" "),r("li",[r("p",[e._v("From "),r("em",[e._v("QGroundControl")]),e._v(":")]),e._v(" "),r("p",[e._v("Click on "),r("strong",[e._v("Trigger Camera")]),e._v(" in the main instrument panel. 이러한 샷은 위치 정보 태그 지정을 위해 기록되거나 계산되지 않습니다.")]),e._v(" "),r("p",[r("img",{attrs:{src:a(1127),alt:"QGC 테스트 카메라"}})])])]),e._v(" "),r("h2",{attrs:{id:"sony-qx-1-example-photogrammetry"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#sony-qx-1-example-photogrammetry"}},[e._v("#")]),e._v(" Sony QX-1 example (Photogrammetry)")]),e._v(" "),r("p",[r("img",{attrs:{src:a(1128),alt:"photogrammetry"}})]),e._v(" "),r("p",[e._v("In this example, we will use a Seagull MAP2 trigger cable to interface to a Sony QX-1 and use the setup to create orthomosaics after flying a fully autonomous survey mission.")]),e._v(" "),r("h3",{attrs:{id:"trigger-settings"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#trigger-settings"}},[e._v("#")]),e._v(" Trigger Settings")]),e._v(" "),r("p",[e._v("The recommended camera settings are:")]),e._v(" "),r("ul",[r("li",[r("code",[e._v("TRIG_INTERFACE=2")]),e._v(" (Seagull MAP2).")]),e._v(" "),r("li",[r("code",[e._v("TRIG_MODE=4")]),e._v(" (Mission controlled).")]),e._v(" "),r("li",[e._v("Leave the remaining parameters at their defaults.")])]),e._v(" "),r("p",[e._v("You will need to connect the Seagull MAP2 to the auxiliary/FMU pins on your autopilot. Pin 1 goes to "),r("code",[e._v("AUX 5")]),e._v(", and Pin 2 to "),r("code",[e._v("AUX 6")]),e._v('. The other end of the MAP2 cable will go into the QX-1\'s "MULTI" port.')]),e._v(" "),r("h3",{attrs:{id:"camera-configuration"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#camera-configuration"}},[e._v("#")]),e._v(" Camera Configuration")]),e._v(" "),r("p",[e._v("We use a Sony QX-1 with a 16-50mm f3.5-5.6 lens for this example.")]),e._v(" "),r("p",[e._v("To avoid autofocus and metering lag when the camera is triggered, the following guidelines should be followed:")]),e._v(" "),r("ul",[r("li",[e._v("Manual focus to infinity")]),e._v(" "),r("li",[e._v("Set camera to continuous shooting mode")]),e._v(" "),r("li",[e._v("Manually set exposure and aperture")]),e._v(" "),r("li",[e._v("ISO should be set as low as possible")]),e._v(" "),r("li",[e._v("Manual white balance suitable for scene")])]),e._v(" "),r("h3",{attrs:{id:"mission-planning"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#mission-planning"}},[e._v("#")]),e._v(" Mission Planning")]),e._v(" "),r("p",[r("img",{attrs:{src:a(1129),alt:"QGC Survey Polygon"}})]),e._v(" "),r("p",[r("img",{attrs:{src:a(1130),alt:"QGC Survey Parameters"}})]),e._v(" "),r("h3",{attrs:{id:"geotagging"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#geotagging"}},[e._v("#")]),e._v(" Geotagging")]),e._v(" "),r("p",[e._v('Download/copy the logfile and images from the flight and point QGroundControl to them. Then click on "Start Tagging".')]),e._v(" "),r("p",[r("img",{attrs:{src:a(1131),alt:"QGC Geotagging"}})]),e._v(" "),r("p",[e._v("You can verify the geotagging using a free online service like "),r("a",{attrs:{href:"https://www.pic2map.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Pic2Map"),r("OutboundLink")],1),e._v(". Note that Pic2Map is limited to only 40 images.")]),e._v(" "),r("h3",{attrs:{id:"reconstruction"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#reconstruction"}},[e._v("#")]),e._v(" Reconstruction")]),e._v(" "),r("p",[e._v("We use "),r("a",{attrs:{href:"https://pix4d.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Pix4D"),r("OutboundLink")],1),e._v(" for 3D reconstruction.")]),e._v(" "),r("p",[r("img",{attrs:{src:a(1132),alt:"GeoTag"}})]),e._v(" "),r("h2",{attrs:{id:"camera-imu-sync-example-vio"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#camera-imu-sync-example-vio"}},[e._v("#")]),e._v(" Camera-IMU sync example (VIO)")]),e._v(" "),r("p",[e._v("In this example, we will go over the basics of synchronising IMU measurements with visual data to build a stereo Visual-Inertial Navigation System (VINS). To be clear, the idea here isn't to take an IMU measurement exactly at the same time as we take a picture but rather to correctly time stamp our images so as to provide accurate data to our VIO algorithm.")]),e._v(" "),r("p",[e._v("The autopilot and companion have different clock bases (boot-time for the autopilot and UNIX epoch for companion), so instead of skewing either clock, we directly observe the time offset between the clocks. This offset is added or subtracted from the timestamps in the MAVLink messages (e.g "),r("code",[e._v("HIGHRES_IMU")]),e._v(") in the cross-middleware translator component (e.g MAVROS on the companion and "),r("code",[e._v("mavlink_receiver")]),e._v(" in PX4). The actual synchronisation algorithm is a modified version of the Network Time Protocol (NTP) algorithm and uses an exponential moving average to smooth the tracked time offset. This synchronisation is done automatically if MAVROS is used with a high-bandwidth onboard link (MAVLink mode "),r("code",[e._v("onboard")]),e._v(").")]),e._v(" "),r("p",[e._v("For acquiring synchronised image frames and inertial measurements, we connect the trigger inputs of the two cameras to a GPIO pin on the autopilot. The timestamp of the inertial measurement from start of exposure and a image sequence number is recorded and sent to the companion computer ("),r("code",[e._v("CAMERA_TRIGGER")]),e._v(" message), which buffers these packets and the image frames acquired from the camera. They are matched based on the sequence number (first image frame is sequence 0), the images timestamped (with the timestamp from the "),r("code",[e._v("CAMERA_TRIGGER")]),e._v(" message) and then published.")]),e._v(" "),r("p",[e._v("The following diagram illustrates the sequence of events which must happen in order to correctly timestamp our images.")]),e._v(" "),r("p",[r("img",{attrs:{src:a(1133),alt:"Sequence diag"}})]),e._v(" "),r("h3",{attrs:{id:"step-1"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#step-1"}},[e._v("#")]),e._v(" Step 1")]),e._v(" "),r("p",[e._v("First, set the TRIG_MODE to 1 to make the driver wait for the start command and reboot your FCU to obtain the remaining parameters.")]),e._v(" "),r("h3",{attrs:{id:"step-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#step-2"}},[e._v("#")]),e._v(" Step 2")]),e._v(" "),r("p",[e._v("For the purposes of this example we will be configuring the trigger to operate in conjunction with a Point Grey Firefly MV camera running at 30 FPS.")]),e._v(" "),r("ul",[r("li",[r("code",[e._v("TRIG_INTERVAL")]),e._v(": 33.33 ms")]),e._v(" "),r("li",[r("code",[e._v("TRIG_POLARITY")]),e._v(": 0 (active low)")]),e._v(" "),r("li",[r("code",[e._v("TRIG_ACT_TIME")]),e._v(": 0.5 ms. The manual specifies it only has to be a minimum of 1 microsecond.")]),e._v(" "),r("li",[r("code",[e._v("TRIG_MODE")]),e._v(": 1, because we want our camera driver to be ready to receive images before starting to trigger. This is essential to properly process sequence numbers.")]),e._v(" "),r("li",[r("code",[e._v("TRIG_PINS")]),e._v(": 56, Leave default.")])]),e._v(" "),r("h3",{attrs:{id:"step-3"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#step-3"}},[e._v("#")]),e._v(" Step 3")]),e._v(" "),r("p",[e._v("Wire up your cameras to your AUX port by connecting the ground and signal pins to the appropriate place.")]),e._v(" "),r("h3",{attrs:{id:"step-4"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#step-4"}},[e._v("#")]),e._v(" Step 4")]),e._v(" "),r("p",[e._v("You will have to modify your driver to follow the sequence diagram above. Public reference implementations for "),r("a",{attrs:{href:"https://github.com/ProjectArtemis/ueye_cam",target:"_blank",rel:"noopener noreferrer"}},[e._v("IDS Imaging UEye"),r("OutboundLink")],1),e._v(" cameras and for "),r("a",{attrs:{href:"https://github.com/andre-nguyen/camera1394",target:"_blank",rel:"noopener noreferrer"}},[e._v("IEEE1394 compliant"),r("OutboundLink")],1),e._v(" cameras are available.")])])}),[],!1,null,null,null);t.default=o.exports}}]);